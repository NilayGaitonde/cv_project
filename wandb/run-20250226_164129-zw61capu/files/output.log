Using device: mps
Training epoch 1/20
Epoch 1/20, Iteration 1/980, Loss: 0.2308
Epoch 1/20, Iteration 2/980, Loss: 0.2995
Epoch 1/20, Iteration 3/980, Loss: 0.2413
Epoch 1/20, Iteration 4/980, Loss: 0.2426
Epoch 1/20, Iteration 5/980, Loss: 0.2712
Epoch 1/20, Iteration 6/980, Loss: 0.2533
Epoch 1/20, Iteration 7/980, Loss: 0.2579
Epoch 1/20, Iteration 8/980, Loss: 0.2465
Epoch 1/20, Iteration 9/980, Loss: 0.2634
Epoch 1/20, Iteration 10/980, Loss: 0.2698
Epoch 1/20, Iteration 11/980, Loss: 0.2527
Epoch 1/20, Iteration 12/980, Loss: 0.2515
Epoch 1/20, Iteration 13/980, Loss: 0.2877
Epoch 1/20, Iteration 14/980, Loss: 0.2436
Epoch 1/20, Iteration 15/980, Loss: 0.2644
Epoch 1/20, Iteration 16/980, Loss: 0.2546
Epoch 1/20, Iteration 17/980, Loss: 0.2691
Epoch 1/20, Iteration 18/980, Loss: 0.2690
Epoch 1/20, Iteration 19/980, Loss: 0.2597
Epoch 1/20, Iteration 20/980, Loss: 0.2599
Epoch 1/20, Iteration 21/980, Loss: 0.2606
Epoch 1/20, Iteration 22/980, Loss: 0.2607
Epoch 1/20, Iteration 23/980, Loss: 0.2550
Epoch 1/20, Iteration 24/980, Loss: 0.2526
Epoch 1/20, Iteration 25/980, Loss: 0.2442
Epoch 1/20, Iteration 26/980, Loss: 0.2302
Epoch 1/20, Iteration 27/980, Loss: 0.2736
Epoch 1/20, Iteration 28/980, Loss: 0.2859
Epoch 1/20, Iteration 29/980, Loss: 0.2332
Epoch 1/20, Iteration 30/980, Loss: 0.3240
Epoch 1/20, Iteration 31/980, Loss: 0.2649
Epoch 1/20, Iteration 32/980, Loss: 0.2613
Epoch 1/20, Iteration 33/980, Loss: 0.2921
Epoch 1/20, Iteration 34/980, Loss: 0.2611
Epoch 1/20, Iteration 35/980, Loss: 0.2547
Epoch 1/20, Iteration 36/980, Loss: 0.2589
Epoch 1/20, Iteration 37/980, Loss: 0.2515
Epoch 1/20, Iteration 38/980, Loss: 0.2803
Epoch 1/20, Iteration 39/980, Loss: 0.2636
Epoch 1/20, Iteration 40/980, Loss: 0.2565
Epoch 1/20, Iteration 41/980, Loss: 0.2444
Epoch 1/20, Iteration 42/980, Loss: 0.2577
Epoch 1/20, Iteration 43/980, Loss: 0.2859
Epoch 1/20, Iteration 44/980, Loss: 0.2459
Epoch 1/20, Iteration 45/980, Loss: 0.3151
Epoch 1/20, Iteration 46/980, Loss: 0.2547
Epoch 1/20, Iteration 47/980, Loss: 0.2665
Epoch 1/20, Iteration 48/980, Loss: 0.2618
Epoch 1/20, Iteration 49/980, Loss: 0.2528
Epoch 1/20, Iteration 50/980, Loss: 0.2964
Epoch 1/20, Iteration 51/980, Loss: 0.3004
Epoch 1/20, Iteration 52/980, Loss: 0.2648
Epoch 1/20, Iteration 53/980, Loss: 0.2251
Epoch 1/20, Iteration 54/980, Loss: 0.2594
Epoch 1/20, Iteration 55/980, Loss: 0.2867
Epoch 1/20, Iteration 56/980, Loss: 0.2333
Epoch 1/20, Iteration 57/980, Loss: 0.2743
Epoch 1/20, Iteration 58/980, Loss: 0.3335
Epoch 1/20, Iteration 59/980, Loss: 0.2861
Epoch 1/20, Iteration 60/980, Loss: 0.2531
Epoch 1/20, Iteration 61/980, Loss: 0.2674
Epoch 1/20, Iteration 62/980, Loss: 0.2598
Epoch 1/20, Iteration 63/980, Loss: 0.2622
Epoch 1/20, Iteration 64/980, Loss: 0.2641
Epoch 1/20, Iteration 65/980, Loss: 0.2692
Epoch 1/20, Iteration 66/980, Loss: 0.2671
Epoch 1/20, Iteration 67/980, Loss: 0.2570
Epoch 1/20, Iteration 68/980, Loss: 0.2562
Epoch 1/20, Iteration 69/980, Loss: 0.2628
Epoch 1/20, Iteration 70/980, Loss: 0.2580
Epoch 1/20, Iteration 71/980, Loss: 0.2640
Epoch 1/20, Iteration 72/980, Loss: 0.2746
Epoch 1/20, Iteration 73/980, Loss: 0.2772
Epoch 1/20, Iteration 74/980, Loss: 0.2624
Epoch 1/20, Iteration 75/980, Loss: 0.2489
Epoch 1/20, Iteration 76/980, Loss: 0.2507
Epoch 1/20, Iteration 77/980, Loss: 0.2597
Epoch 1/20, Iteration 78/980, Loss: 0.2875
Epoch 1/20, Iteration 79/980, Loss: 0.2275
Epoch 1/20, Iteration 80/980, Loss: 0.2570
Epoch 1/20, Iteration 81/980, Loss: 0.2677
Epoch 1/20, Iteration 82/980, Loss: 0.2232
Epoch 1/20, Iteration 83/980, Loss: 0.2587
Epoch 1/20, Iteration 84/980, Loss: 0.2715
Epoch 1/20, Iteration 85/980, Loss: 0.2775
Epoch 1/20, Iteration 86/980, Loss: 0.2725
Epoch 1/20, Iteration 87/980, Loss: 0.2383
Epoch 1/20, Iteration 88/980, Loss: 0.2626
Epoch 1/20, Iteration 89/980, Loss: 0.2657
Epoch 1/20, Iteration 90/980, Loss: 0.2751
Epoch 1/20, Iteration 91/980, Loss: 0.2565
Epoch 1/20, Iteration 92/980, Loss: 0.2602
Epoch 1/20, Iteration 93/980, Loss: 0.2647
Epoch 1/20, Iteration 94/980, Loss: 0.2685
Epoch 1/20, Iteration 95/980, Loss: 0.2813
Epoch 1/20, Iteration 96/980, Loss: 0.2485
Epoch 1/20, Iteration 97/980, Loss: 0.2637
Epoch 1/20, Iteration 98/980, Loss: 0.2656
Epoch 1/20, Iteration 99/980, Loss: 0.2776
Epoch 1/20, Iteration 100/980, Loss: 0.2632
Epoch 1/20, Iteration 101/980, Loss: 0.2644
Epoch 1/20, Iteration 102/980, Loss: 0.2535
Epoch 1/20, Iteration 103/980, Loss: 0.2704
Epoch 1/20, Iteration 104/980, Loss: 0.2624
Epoch 1/20, Iteration 105/980, Loss: 0.2599
Epoch 1/20, Iteration 106/980, Loss: 0.2662
Epoch 1/20, Iteration 107/980, Loss: 0.2932
Epoch 1/20, Iteration 108/980, Loss: 0.2603
Epoch 1/20, Iteration 109/980, Loss: 0.2626
Epoch 1/20, Iteration 110/980, Loss: 0.2600
Epoch 1/20, Iteration 111/980, Loss: 0.2579
Epoch 1/20, Iteration 112/980, Loss: 0.2668
Epoch 1/20, Iteration 113/980, Loss: 0.2525
Epoch 1/20, Iteration 114/980, Loss: 0.2837
Epoch 1/20, Iteration 115/980, Loss: 0.2716
Epoch 1/20, Iteration 116/980, Loss: 0.2617
Epoch 1/20, Iteration 117/980, Loss: 0.2601
Epoch 1/20, Iteration 118/980, Loss: 0.2758
Epoch 1/20, Iteration 119/980, Loss: 0.2585
Epoch 1/20, Iteration 120/980, Loss: 0.2531
Epoch 1/20, Iteration 121/980, Loss: 0.2606
Epoch 1/20, Iteration 122/980, Loss: 0.2640
Epoch 1/20, Iteration 123/980, Loss: 0.2596
Epoch 1/20, Iteration 124/980, Loss: 0.2653
Epoch 1/20, Iteration 125/980, Loss: 0.2567
Epoch 1/20, Iteration 126/980, Loss: 0.2649
Epoch 1/20, Iteration 127/980, Loss: 0.2677
Epoch 1/20, Iteration 128/980, Loss: 0.2539
Epoch 1/20, Iteration 129/980, Loss: 0.2665
Epoch 1/20, Iteration 130/980, Loss: 0.2380
Epoch 1/20, Iteration 131/980, Loss: 0.2796
Epoch 1/20, Iteration 132/980, Loss: 0.2725
Epoch 1/20, Iteration 133/980, Loss: 0.2377
Epoch 1/20, Iteration 134/980, Loss: 0.2466
Epoch 1/20, Iteration 135/980, Loss: 0.2733
Epoch 1/20, Iteration 136/980, Loss: 0.2639
Epoch 1/20, Iteration 137/980, Loss: 0.2565
Epoch 1/20, Iteration 138/980, Loss: 0.2619
Epoch 1/20, Iteration 139/980, Loss: 0.2590
Epoch 1/20, Iteration 140/980, Loss: 0.2685
Epoch 1/20, Iteration 141/980, Loss: 0.2601
Epoch 1/20, Iteration 142/980, Loss: 0.2637
Epoch 1/20, Iteration 143/980, Loss: 0.2598
Epoch 1/20, Iteration 144/980, Loss: 0.2657
Epoch 1/20, Iteration 145/980, Loss: 0.2621
Epoch 1/20, Iteration 146/980, Loss: 0.2659
Epoch 1/20, Iteration 147/980, Loss: 0.2580
Epoch 1/20, Iteration 148/980, Loss: 0.2693
Epoch 1/20, Iteration 149/980, Loss: 0.2606
Epoch 1/20, Iteration 150/980, Loss: 0.2632
Epoch 1/20, Iteration 151/980, Loss: 0.2556
Epoch 1/20, Iteration 152/980, Loss: 0.2472
Epoch 1/20, Iteration 153/980, Loss: 0.2565
Epoch 1/20, Iteration 154/980, Loss: 0.2494
Epoch 1/20, Iteration 155/980, Loss: 0.2802
Epoch 1/20, Iteration 156/980, Loss: 0.2268
Epoch 1/20, Iteration 157/980, Loss: 0.3126
Epoch 1/20, Iteration 158/980, Loss: 0.2772
Epoch 1/20, Iteration 159/980, Loss: 0.2450
Epoch 1/20, Iteration 160/980, Loss: 0.2928
Epoch 1/20, Iteration 161/980, Loss: 0.2600
Epoch 1/20, Iteration 162/980, Loss: 0.2445
Epoch 1/20, Iteration 163/980, Loss: 0.2668
Epoch 1/20, Iteration 164/980, Loss: 0.2646
Epoch 1/20, Iteration 165/980, Loss: 0.2774
Epoch 1/20, Iteration 166/980, Loss: 0.2681
Epoch 1/20, Iteration 167/980, Loss: 0.2467
Epoch 1/20, Iteration 168/980, Loss: 0.2357
Epoch 1/20, Iteration 169/980, Loss: 0.2889
Epoch 1/20, Iteration 170/980, Loss: 0.3115
Epoch 1/20, Iteration 171/980, Loss: 0.2799
Epoch 1/20, Iteration 172/980, Loss: 0.2645
Epoch 1/20, Iteration 173/980, Loss: 0.2621
Epoch 1/20, Iteration 174/980, Loss: 0.2641
Epoch 1/20, Iteration 175/980, Loss: 0.2537
Epoch 1/20, Iteration 176/980, Loss: 0.2740
Epoch 1/20, Iteration 177/980, Loss: 0.2548
Epoch 1/20, Iteration 178/980, Loss: 0.2572
Epoch 1/20, Iteration 179/980, Loss: 0.2638
Epoch 1/20, Iteration 180/980, Loss: 0.2633
Epoch 1/20, Iteration 181/980, Loss: 0.2467
Epoch 1/20, Iteration 182/980, Loss: 0.2455
Epoch 1/20, Iteration 183/980, Loss: 0.2864
Epoch 1/20, Iteration 184/980, Loss: 0.2824
Epoch 1/20, Iteration 185/980, Loss: 0.2622
Epoch 1/20, Iteration 186/980, Loss: 0.2471
Epoch 1/20, Iteration 187/980, Loss: 0.2611
Epoch 1/20, Iteration 188/980, Loss: 0.2564
Epoch 1/20, Iteration 189/980, Loss: 0.2829
Epoch 1/20, Iteration 190/980, Loss: 0.2930
Epoch 1/20, Iteration 191/980, Loss: 0.2563
Epoch 1/20, Iteration 192/980, Loss: 0.2914
Epoch 1/20, Iteration 193/980, Loss: 0.2665
Epoch 1/20, Iteration 194/980, Loss: 0.2615
Epoch 1/20, Iteration 195/980, Loss: 0.2671
Epoch 1/20, Iteration 196/980, Loss: 0.2404
Epoch 1/20, Iteration 197/980, Loss: 0.2609
Epoch 1/20, Iteration 198/980, Loss: 0.2670
Epoch 1/20, Iteration 199/980, Loss: 0.2499
Epoch 1/20, Iteration 200/980, Loss: 0.2619
Epoch 1/20, Iteration 201/980, Loss: 0.2466
Epoch 1/20, Iteration 202/980, Loss: 0.2393
Epoch 1/20, Iteration 203/980, Loss: 0.2707
Epoch 1/20, Iteration 204/980, Loss: 0.2864
Epoch 1/20, Iteration 205/980, Loss: 0.2149
Epoch 1/20, Iteration 206/980, Loss: 0.3034
Epoch 1/20, Iteration 207/980, Loss: 0.2740
Epoch 1/20, Iteration 208/980, Loss: 0.2503
Epoch 1/20, Iteration 209/980, Loss: 0.2606
Epoch 1/20, Iteration 210/980, Loss: 0.2622
Epoch 1/20, Iteration 211/980, Loss: 0.2664
Epoch 1/20, Iteration 212/980, Loss: 0.2638
Epoch 1/20, Iteration 213/980, Loss: 0.2610
Epoch 1/20, Iteration 214/980, Loss: 0.2560
Epoch 1/20, Iteration 215/980, Loss: 0.2679
Epoch 1/20, Iteration 216/980, Loss: 0.2637
Epoch 1/20, Iteration 217/980, Loss: 0.2744
Epoch 1/20, Iteration 218/980, Loss: 0.2605
Epoch 1/20, Iteration 219/980, Loss: 0.2624
Epoch 1/20, Iteration 220/980, Loss: 0.2686
Epoch 1/20, Iteration 221/980, Loss: 0.2681
Epoch 1/20, Iteration 222/980, Loss: 0.2579
Epoch 1/20, Iteration 223/980, Loss: 0.2536
Epoch 1/20, Iteration 224/980, Loss: 0.2726
Epoch 1/20, Iteration 225/980, Loss: 0.2598
Epoch 1/20, Iteration 226/980, Loss: 0.2577
Epoch 1/20, Iteration 227/980, Loss: 0.2550
Epoch 1/20, Iteration 228/980, Loss: 0.2647
Epoch 1/20, Iteration 229/980, Loss: 0.2509
Epoch 1/20, Iteration 230/980, Loss: 0.2842
Epoch 1/20, Iteration 231/980, Loss: 0.2682
Epoch 1/20, Iteration 232/980, Loss: 0.2624
Epoch 1/20, Iteration 233/980, Loss: 0.2736
Epoch 1/20, Iteration 234/980, Loss: 0.2565
Epoch 1/20, Iteration 235/980, Loss: 0.2573
Epoch 1/20, Iteration 236/980, Loss: 0.2550
Epoch 1/20, Iteration 237/980, Loss: 0.2477
Epoch 1/20, Iteration 238/980, Loss: 0.2896
Epoch 1/20, Iteration 239/980, Loss: 0.2602
Epoch 1/20, Iteration 240/980, Loss: 0.2529
Epoch 1/20, Iteration 241/980, Loss: 0.2619
Epoch 1/20, Iteration 242/980, Loss: 0.2558
Epoch 1/20, Iteration 243/980, Loss: 0.2648
Epoch 1/20, Iteration 244/980, Loss: 0.2620
Epoch 1/20, Iteration 245/980, Loss: 0.2653
Epoch 1/20, Iteration 246/980, Loss: 0.2575
Epoch 1/20, Iteration 247/980, Loss: 0.2420
Epoch 1/20, Iteration 248/980, Loss: 0.2545
Epoch 1/20, Iteration 249/980, Loss: 0.2627
Epoch 1/20, Iteration 250/980, Loss: 0.2658
Epoch 1/20, Iteration 251/980, Loss: 0.2594
Epoch 1/20, Iteration 252/980, Loss: 0.2688
Epoch 1/20, Iteration 253/980, Loss: 0.2418
Epoch 1/20, Iteration 254/980, Loss: 0.2628
Epoch 1/20, Iteration 255/980, Loss: 0.2623
Epoch 1/20, Iteration 256/980, Loss: 0.2485
Epoch 1/20, Iteration 257/980, Loss: 0.2698
Epoch 1/20, Iteration 258/980, Loss: 0.2383
Epoch 1/20, Iteration 259/980, Loss: 0.2566
Epoch 1/20, Iteration 260/980, Loss: 0.2784
Epoch 1/20, Iteration 261/980, Loss: 0.2574
Epoch 1/20, Iteration 262/980, Loss: 0.2601
Epoch 1/20, Iteration 263/980, Loss: 0.2608
Epoch 1/20, Iteration 264/980, Loss: 0.2624
Epoch 1/20, Iteration 265/980, Loss: 0.2719
Epoch 1/20, Iteration 266/980, Loss: 0.2617
Epoch 1/20, Iteration 267/980, Loss: 0.2622
Epoch 1/20, Iteration 268/980, Loss: 0.2586
Epoch 1/20, Iteration 269/980, Loss: 0.2582
Epoch 1/20, Iteration 270/980, Loss: 0.2558
Epoch 1/20, Iteration 271/980, Loss: 0.2582
Epoch 1/20, Iteration 272/980, Loss: 0.2725
Epoch 1/20, Iteration 273/980, Loss: 0.2453
Epoch 1/20, Iteration 274/980, Loss: 0.2494
Epoch 1/20, Iteration 275/980, Loss: 0.3080
Epoch 1/20, Iteration 276/980, Loss: 0.2685
Epoch 1/20, Iteration 277/980, Loss: 0.2664
Epoch 1/20, Iteration 278/980, Loss: 0.2556
Epoch 1/20, Iteration 279/980, Loss: 0.2825
Epoch 1/20, Iteration 280/980, Loss: 0.2590
Epoch 1/20, Iteration 281/980, Loss: 0.2616
Epoch 1/20, Iteration 282/980, Loss: 0.2497
Epoch 1/20, Iteration 283/980, Loss: 0.2534
Epoch 1/20, Iteration 284/980, Loss: 0.3007
Epoch 1/20, Iteration 285/980, Loss: 0.2921
Epoch 1/20, Iteration 286/980, Loss: 0.2447
Epoch 1/20, Iteration 287/980, Loss: 0.2641
Epoch 1/20, Iteration 288/980, Loss: 0.2573
Epoch 1/20, Iteration 289/980, Loss: 0.2554
Epoch 1/20, Iteration 290/980, Loss: 0.2564
Epoch 1/20, Iteration 291/980, Loss: 0.2625
Epoch 1/20, Iteration 292/980, Loss: 0.2618
Epoch 1/20, Iteration 293/980, Loss: 0.2648
Epoch 1/20, Iteration 294/980, Loss: 0.2664
Epoch 1/20, Iteration 295/980, Loss: 0.2531
Epoch 1/20, Iteration 296/980, Loss: 0.2637
Epoch 1/20, Iteration 297/980, Loss: 0.2907
Epoch 1/20, Iteration 298/980, Loss: 0.2670
Epoch 1/20, Iteration 299/980, Loss: 0.2557
Epoch 1/20, Iteration 300/980, Loss: 0.2584
Epoch 1/20, Iteration 301/980, Loss: 0.2560
Epoch 1/20, Iteration 302/980, Loss: 0.2644
Epoch 1/20, Iteration 303/980, Loss: 0.2555
Epoch 1/20, Iteration 304/980, Loss: 0.2587
Epoch 1/20, Iteration 305/980, Loss: 0.2548
Epoch 1/20, Iteration 306/980, Loss: 0.2612
Epoch 1/20, Iteration 307/980, Loss: 0.2560
Epoch 1/20, Iteration 308/980, Loss: 0.2582
Epoch 1/20, Iteration 309/980, Loss: 0.2645
Epoch 1/20, Iteration 310/980, Loss: 0.2646
Epoch 1/20, Iteration 311/980, Loss: 0.2568
Epoch 1/20, Iteration 312/980, Loss: 0.2576
Epoch 1/20, Iteration 313/980, Loss: 0.2593
Epoch 1/20, Iteration 314/980, Loss: 0.2605
Epoch 1/20, Iteration 315/980, Loss: 0.2484
Epoch 1/20, Iteration 316/980, Loss: 0.2608
Epoch 1/20, Iteration 317/980, Loss: 0.2635
Epoch 1/20, Iteration 318/980, Loss: 0.2515
Epoch 1/20, Iteration 319/980, Loss: 0.2568
Epoch 1/20, Iteration 320/980, Loss: 0.2557
Epoch 1/20, Iteration 321/980, Loss: 0.2645
Epoch 1/20, Iteration 322/980, Loss: 0.2610
Epoch 1/20, Iteration 323/980, Loss: 0.2640
Epoch 1/20, Iteration 324/980, Loss: 0.2610
Epoch 1/20, Iteration 325/980, Loss: 0.2548
Epoch 1/20, Iteration 326/980, Loss: 0.2491
Traceback (most recent call last):
  File "/Users/nilaygaitonde/Documents/Projects/capstone/siamese.py", line 237, in <module>
    trained_model, training_loss, validation_loss = training(model, train_dataloader, val_dataloader, epochs=20, lr=0.001)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nilaygaitonde/Documents/Projects/capstone/siamese.py", line 147, in training
    loss.backward()
  File "/Users/nilaygaitonde/anaconda3/envs/deeplearning/lib/python3.12/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/Users/nilaygaitonde/anaconda3/envs/deeplearning/lib/python3.12/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/Users/nilaygaitonde/anaconda3/envs/deeplearning/lib/python3.12/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt